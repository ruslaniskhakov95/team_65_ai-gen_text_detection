{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69d1373e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/ruslanishakov/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/ruslanishakov/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/ruslanishakov/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/ruslanishakov/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from nltk import tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import string\n",
    "from collections import Counter\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95ee9bfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>generated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Driverless cars have always been seen and thou...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Electoral College is only taking your pers...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Distance learning recently started being consi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Distractions while driving could lead to death...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Would having car free cities be easier for eve...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15395</th>\n",
       "      <td>Should students have classes from home, base i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15396</th>\n",
       "      <td>Driveress cars are in our future because of al...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15397</th>\n",
       "      <td>Are dreiverless cars a good idea for the futur...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15398</th>\n",
       "      <td>Sometimes school can be to much for a person. ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15399</th>\n",
       "      <td>summer project should be student-designed. For...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15400 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  generated\n",
       "0      Driverless cars have always been seen and thou...          0\n",
       "1      The Electoral College is only taking your pers...          0\n",
       "2      Distance learning recently started being consi...          0\n",
       "3      Distractions while driving could lead to death...          0\n",
       "4      Would having car free cities be easier for eve...          0\n",
       "...                                                  ...        ...\n",
       "15395  Should students have classes from home, base i...          0\n",
       "15396  Driveress cars are in our future because of al...          0\n",
       "15397  Are dreiverless cars a good idea for the futur...          0\n",
       "15398  Sometimes school can be to much for a person. ...          0\n",
       "15399  summer project should be student-designed. For...          0\n",
       "\n",
       "[15400 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pickl_h_train = pd.read_pickle('dataset/outfox/human/train_humans.pkl')\n",
    "pickl_h_test = pd.read_pickle('dataset/outfox/human/test_humans.pkl')\n",
    "pickl_h_valid = pd.read_pickle('dataset/outfox/human/valid_humans.pkl')\n",
    "df_human_test = pd.DataFrame(pickl_h_test)\n",
    "df_human_train = pd.DataFrame(pickl_h_train)\n",
    "df_human_valid = pd.DataFrame(pickl_h_valid)\n",
    "df_human = pd.concat([df_human_train, df_human_test, df_human_valid], ignore_index=True)\n",
    "df_human.rename(columns={0: 'text'}, inplace=True)\n",
    "df_human['generated'] = 0\n",
    "df_human"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f66d5164",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>generated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\nDriverless cars have been heralded as a grou...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Electoral College system is controversial ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The global coronavirus pandemic has had signi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Texting and driving is distracting and dangero...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The growth of urbanism and improved transporta...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15395</th>\n",
       "      <td>In the digital age, the age-old debate of whet...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15396</th>\n",
       "      <td>Driverless cars could dramatically reduce the ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15397</th>\n",
       "      <td>Driverless cars could revolutionize contempora...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15398</th>\n",
       "      <td>Going to school can be a bit of a bummer. Writ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15399</th>\n",
       "      <td>\\nAllowing students to design their own summe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15400 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  generated\n",
       "0      \\nDriverless cars have been heralded as a grou...          1\n",
       "1      The Electoral College system is controversial ...          1\n",
       "2       The global coronavirus pandemic has had signi...          1\n",
       "3      Texting and driving is distracting and dangero...          1\n",
       "4      The growth of urbanism and improved transporta...          1\n",
       "...                                                  ...        ...\n",
       "15395  In the digital age, the age-old debate of whet...          1\n",
       "15396  Driverless cars could dramatically reduce the ...          1\n",
       "15397  Driverless cars could revolutionize contempora...          1\n",
       "15398  Going to school can be a bit of a bummer. Writ...          1\n",
       "15399   \\nAllowing students to design their own summe...          1\n",
       "\n",
       "[15400 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pickl_davinci_train = pd.read_pickle('dataset/outfox/davinci/train_lms_davinci.pkl')\n",
    "pickl_davinci_test = pd.read_pickle('dataset/outfox/davinci/test_lms_davinci.pkl')\n",
    "pickl_davinci_valid = pd.read_pickle('dataset/outfox/davinci/valid_lms_davinci.pkl')\n",
    "df_davinci_train = pd.DataFrame(pickl_davinci_train)\n",
    "df_davinci_test = pd.DataFrame(pickl_davinci_test)\n",
    "df_davinci_valid = pd.DataFrame(pickl_davinci_valid)\n",
    "df_davinci = pd.concat([df_davinci_train, df_davinci_test, df_davinci_valid], ignore_index=True)\n",
    "df_davinci.rename(columns={0: 'text'}, inplace=True)\n",
    "df_davinci['generated'] = 1\n",
    "df_davinci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd91954f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df_human, df_davinci], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82212a21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>generated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>It is a better choice asking more than one per...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\nMeaningful dialogue between educators and st...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The importance of the Electoral College in the...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\nParticipating in the Seagoing Cowboys progra...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I overheard that you are thinking on should we...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30795</th>\n",
       "      <td>\\nIn recent years, mandating students to take ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30796</th>\n",
       "      <td>Choices are the essence of experiencing life t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30797</th>\n",
       "      <td>Making decisions can be one of the most diffic...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30798</th>\n",
       "      <td>Many Americans enjoy technologies advancement ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30799</th>\n",
       "      <td>\\nSince the emergence of the internet and new ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30715 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  generated\n",
       "0      It is a better choice asking more than one per...          0\n",
       "1      \\nMeaningful dialogue between educators and st...          1\n",
       "2      The importance of the Electoral College in the...          1\n",
       "3      \\nParticipating in the Seagoing Cowboys progra...          1\n",
       "4      I overheard that you are thinking on should we...          0\n",
       "...                                                  ...        ...\n",
       "30795  \\nIn recent years, mandating students to take ...          1\n",
       "30796  Choices are the essence of experiencing life t...          1\n",
       "30797  Making decisions can be one of the most diffic...          1\n",
       "30798  Many Americans enjoy technologies advancement ...          0\n",
       "30799  \\nSince the emergence of the internet and new ...          1\n",
       "\n",
       "[30715 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.sample(30800).reset_index(drop=True)\n",
    "df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "205739ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_clean_text(text):\n",
    "    tokens = tokenize.word_tokenize(text)\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    punct_chars = string.punctuation + \"'s\" + '\"\"' + '...' + \"''\" + '``'\n",
    "    filtered_tokens = [word.lower() for word in tokens if word not in stop_words and word not in punct_chars]\n",
    "    return filtered_tokens\n",
    "\n",
    "def lemmatize(tokens):\n",
    "    lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "    return [lemmatizer.lemmatize(token) for token in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67d1b3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['text']\n",
    "y = df['generated']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4006ac14",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_cleaned_lemm = []\n",
    "for text in X.apply(tokenize_and_clean_text).apply(lemmatize):\n",
    "    corpus_cleaned_lemm.append(' '.join(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "651b409b",
   "metadata": {},
   "source": [
    "Load models and vectorizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b590b30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_filename = 'model_log_vec.pkl'\n",
    "with open(model_filename, 'rb') as model_file:\n",
    "    loaded_model_vec = pickle.load(model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f72a1135",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_filename = 'model_log_tfidf.pkl'\n",
    "with open(model_filename, 'rb') as model_file:\n",
    "    loaded_model_tfidf = pickle.load(model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "488ee7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_filename = 'count_vectorizer_uni.pkl'\n",
    "with open(vec_filename, 'rb') as vec_file:\n",
    "    loaded_cnt_vec = pickle.load(vec_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e91bc64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_filename = 'tfidf_vectorizer_uni.pkl'\n",
    "with open(vec_filename, 'rb') as vec_file:\n",
    "    loaded_tfidf_vec = pickle.load(vec_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c62a841",
   "metadata": {},
   "source": [
    "### LogReg Models based on CountVectorizer and TfIdfVectorizer respectively, trained on 30800 essays from ChatGPT-Human dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8c363e91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00     15400\n",
      "           1       1.00      0.99      1.00     15400\n",
      "\n",
      "    accuracy                           1.00     30800\n",
      "   macro avg       1.00      1.00      1.00     30800\n",
      "weighted avg       1.00      1.00      1.00     30800\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "X_vec = loaded_cnt_vec.transform(corpus_cleaned_lemm)\n",
    "pred_vec = loaded_model_vec.predict(X_vec)\n",
    "print(print(classification_report(y, pred_vec)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e235c0c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     15400\n",
      "           1       1.00      1.00      1.00     15400\n",
      "\n",
      "    accuracy                           1.00     30800\n",
      "   macro avg       1.00      1.00      1.00     30800\n",
      "weighted avg       1.00      1.00      1.00     30800\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "probs = loaded_model_vec.predict_proba(X_vec)\n",
    "new_pred = np.where(probs[:, 1] > 0.4, 1, 0)\n",
    "print(print(classification_report(y, new_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "127a9731",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.97      0.95     15400\n",
      "           1       0.97      0.93      0.95     15400\n",
      "\n",
      "    accuracy                           0.95     30800\n",
      "   macro avg       0.95      0.95      0.95     30800\n",
      "weighted avg       0.95      0.95      0.95     30800\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "X_tfidf = loaded_tfidf_vec.transform(corpus_cleaned_lemm)\n",
    "pred_tf = loaded_model_tfidf.predict(X_tfidf)\n",
    "print(print(classification_report(y, pred_tf)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "19d74751",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.97      0.95     15400\n",
      "           1       0.97      0.93      0.95     15400\n",
      "\n",
      "    accuracy                           0.95     30800\n",
      "   macro avg       0.95      0.95      0.95     30800\n",
      "weighted avg       0.95      0.95      0.95     30800\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "probs_2 = loaded_model_tfidf.predict_proba(X_tfidf)\n",
    "new_pred_2 = np.where(probs_2[:, 1] > 0.5, 1, 0)\n",
    "print(print(classification_report(y, new_pred_2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "789184a6",
   "metadata": {},
   "source": [
    "Own models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "350e4923",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['text']\n",
    "y = df['generated']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3855745e",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_cleaned_lemm_train = []\n",
    "corpus_cleaned_lemm_test = []\n",
    "for text in X_train.apply(tokenize_and_clean_text).apply(lemmatize):\n",
    "    corpus_cleaned_lemm_train.append(' '.join(text))\n",
    "for text in X_test.apply(tokenize_and_clean_text).apply(lemmatize):\n",
    "    corpus_cleaned_lemm_test.append(' '.join(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "156a082a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(max_features=100)\n",
    "tfidf_vectorizer.fit(X_train)\n",
    "X_train_tfidf = tfidf_vectorizer.transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8b89e60c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98     10817\n",
      "           1       0.98      0.99      0.98     10743\n",
      "\n",
      "    accuracy                           0.98     21560\n",
      "   macro avg       0.98      0.98      0.98     21560\n",
      "weighted avg       0.98      0.98      0.98     21560\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98      4583\n",
      "           1       0.98      0.98      0.98      4657\n",
      "\n",
      "    accuracy                           0.98      9240\n",
      "   macro avg       0.98      0.98      0.98      9240\n",
      "weighted avg       0.98      0.98      0.98      9240\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "y_pred_train = model.predict(X_train_tfidf)\n",
    "print(classification_report(y_train, y_pred_train))\n",
    "print()\n",
    "\n",
    "y_pred = model.predict(X_test_tfidf)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122257f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4e496253",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vec_bi = TfidfVectorizer(ngram_range=(2, 2), max_features=100)\n",
    "tfidf_vec_bi.fit(corpus_cleaned_lemm_train)\n",
    "X_train_tfidf = tfidf_vec_bi.transform(corpus_cleaned_lemm_train)\n",
    "X_test_tfidf = tfidf_vec_bi.transform(corpus_cleaned_lemm_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ae14b266",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.78      0.82     10817\n",
      "           1       0.80      0.86      0.83     10743\n",
      "\n",
      "    accuracy                           0.82     21560\n",
      "   macro avg       0.82      0.82      0.82     21560\n",
      "weighted avg       0.82      0.82      0.82     21560\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.77      0.81      4583\n",
      "           1       0.79      0.87      0.83      4657\n",
      "\n",
      "    accuracy                           0.82      9240\n",
      "   macro avg       0.82      0.82      0.82      9240\n",
      "weighted avg       0.82      0.82      0.82      9240\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.70      0.78      4583\n",
      "           1       0.75      0.91      0.83      4657\n",
      "\n",
      "    accuracy                           0.81      9240\n",
      "   macro avg       0.82      0.81      0.80      9240\n",
      "weighted avg       0.82      0.81      0.80      9240\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_2 = LogisticRegression(max_iter=1000)\n",
    "model_2.fit(X_train_tfidf, y_train)\n",
    "\n",
    "y_pred_train_2 = model_2.predict(X_train_tfidf)\n",
    "print(classification_report(y_train, y_pred_train_2))\n",
    "\n",
    "y_pred_test_2 = model_2.predict(X_test_tfidf)\n",
    "print(classification_report(y_test, y_pred_test_2))\n",
    "\n",
    "probs = model_2.predict_proba(X_test_tfidf)\n",
    "pred_probs = np.where(probs[:, 1] > 0.4, 1, 0)\n",
    "print(classification_report(y_test, pred_probs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0dc503",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scikit_venv",
   "language": "python",
   "name": "scikit_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
