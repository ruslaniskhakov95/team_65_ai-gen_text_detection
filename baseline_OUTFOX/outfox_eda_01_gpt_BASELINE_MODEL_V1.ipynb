{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7e88632",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/ruslanishakov/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/ruslanishakov/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/ruslanishakov/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/ruslanishakov/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from nltk import tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import string\n",
    "from collections import Counter\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d929a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_clean_text(text):\n",
    "    tokens = tokenize.word_tokenize(text)\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    punct_chars = string.punctuation + \"'s\" + '\"\"' + '...' + \"''\" + '``'\n",
    "    filtered_tokens = [word.lower() for word in tokens if word not in stop_words and word not in punct_chars]\n",
    "    return filtered_tokens\n",
    "\n",
    "def lemmatize(tokens):\n",
    "    lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "    return [lemmatizer.lemmatize(token) for token in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79601a66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>generated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Driverless cars have always been seen and thou...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Electoral College is only taking your pers...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Distance learning recently started being consi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Distractions while driving could lead to death...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Would having car free cities be easier for eve...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15395</th>\n",
       "      <td>Should students have classes from home, base i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15396</th>\n",
       "      <td>Driveress cars are in our future because of al...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15397</th>\n",
       "      <td>Are dreiverless cars a good idea for the futur...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15398</th>\n",
       "      <td>Sometimes school can be to much for a person. ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15399</th>\n",
       "      <td>summer project should be student-designed. For...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15400 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  generated\n",
       "0      Driverless cars have always been seen and thou...          0\n",
       "1      The Electoral College is only taking your pers...          0\n",
       "2      Distance learning recently started being consi...          0\n",
       "3      Distractions while driving could lead to death...          0\n",
       "4      Would having car free cities be easier for eve...          0\n",
       "...                                                  ...        ...\n",
       "15395  Should students have classes from home, base i...          0\n",
       "15396  Driveress cars are in our future because of al...          0\n",
       "15397  Are dreiverless cars a good idea for the futur...          0\n",
       "15398  Sometimes school can be to much for a person. ...          0\n",
       "15399  summer project should be student-designed. For...          0\n",
       "\n",
       "[15400 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pickl_h_train = pd.read_pickle('dataset/outfox/human/train_humans.pkl')\n",
    "pickl_h_test = pd.read_pickle('dataset/outfox/human/test_humans.pkl')\n",
    "pickl_h_valid = pd.read_pickle('dataset/outfox/human/valid_humans.pkl')\n",
    "df_human_test = pd.DataFrame(pickl_h_test)\n",
    "df_human_train = pd.DataFrame(pickl_h_train)\n",
    "df_human_valid = pd.DataFrame(pickl_h_valid)\n",
    "df_human = pd.concat([df_human_train, df_human_test, df_human_valid], ignore_index=True)\n",
    "df_human.rename(columns={0: 'text'}, inplace=True)\n",
    "df_human['generated'] = 0\n",
    "df_human"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bdf1692a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>generated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The world is rapidly advancing towards advance...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Electoral College is a unique system that ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The COVID-19 pandemic has negatively affected ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Driving is inherently risky, and the chances o...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The issue of car-free cities has gained more a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15395</th>\n",
       "      <td>The idea of students taking classes from home ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15396</th>\n",
       "      <td>Over the past few years, the technology for dr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15397</th>\n",
       "      <td>With technological advancements paving the way...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15398</th>\n",
       "      <td>The educational landscape has undergone a tran...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15399</th>\n",
       "      <td>Allowing students to design their own summer p...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15400 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  generated\n",
       "0      The world is rapidly advancing towards advance...          1\n",
       "1      The Electoral College is a unique system that ...          1\n",
       "2      The COVID-19 pandemic has negatively affected ...          1\n",
       "3      Driving is inherently risky, and the chances o...          1\n",
       "4      The issue of car-free cities has gained more a...          1\n",
       "...                                                  ...        ...\n",
       "15395  The idea of students taking classes from home ...          1\n",
       "15396  Over the past few years, the technology for dr...          1\n",
       "15397  With technological advancements paving the way...          1\n",
       "15398  The educational landscape has undergone a tran...          1\n",
       "15399  Allowing students to design their own summer p...          1\n",
       "\n",
       "[15400 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pickl_gpt_train = pd.read_pickle('dataset/outfox/gpt/train_lms.pkl')\n",
    "pickl_gpt_test = pd.read_pickle('dataset/outfox/gpt/test_lms.pkl')\n",
    "pickl_gpt_valid = pd.read_pickle('dataset/outfox/gpt/valid_lms.pkl')\n",
    "df_gpt_train = pd.DataFrame(pickl_gpt_train)\n",
    "df_gpt_test = pd.DataFrame(pickl_gpt_test)\n",
    "df_gpt_valid = pd.DataFrame(pickl_gpt_valid)\n",
    "df_gpt = pd.concat([df_gpt_train, df_gpt_test, df_gpt_valid], ignore_index=True)\n",
    "df_gpt.rename(columns={0: 'text'}, inplace=True)\n",
    "df_gpt['generated'] = 1\n",
    "df_gpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fed78270",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df_human, df_gpt], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f148238c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(30800).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ecab15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "68114198",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>generated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>For centuries, we have followed a certian syst...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Online schooling has grown in popularity in re...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Driverless cars should not become a reality.  ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Summer assignments have become a staple of mos...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>In \"The Challenge of exploring Venus,\" the aut...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30795</th>\n",
       "      <td>The images of a human-like Face on Mars have p...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30796</th>\n",
       "      <td>Emotions may be hard to understand sometimes, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30797</th>\n",
       "      <td>Engagement in extracurricular activities offer...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30798</th>\n",
       "      <td>Almost every single person that dives a vehicl...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30799</th>\n",
       "      <td>The Seagoing Cowboys program is an incredible ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30715 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  generated\n",
       "0      For centuries, we have followed a certian syst...          0\n",
       "1      Online schooling has grown in popularity in re...          1\n",
       "2      Driverless cars should not become a reality.  ...          0\n",
       "3      Summer assignments have become a staple of mos...          1\n",
       "4      In \"The Challenge of exploring Venus,\" the aut...          0\n",
       "...                                                  ...        ...\n",
       "30795  The images of a human-like Face on Mars have p...          1\n",
       "30796  Emotions may be hard to understand sometimes, ...          0\n",
       "30797  Engagement in extracurricular activities offer...          1\n",
       "30798  Almost every single person that dives a vehicl...          0\n",
       "30799  The Seagoing Cowboys program is an incredible ...          1\n",
       "\n",
       "[30715 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a060c2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['text']\n",
    "y = df['generated']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e15ffe9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_cleaned_lemm_train = []\n",
    "corpus_cleaned_lemm_test = []\n",
    "for text in X_train.apply(tokenize_and_clean_text).apply(lemmatize):\n",
    "    corpus_cleaned_lemm_train.append(' '.join(text))\n",
    "for text in X_test.apply(tokenize_and_clean_text).apply(lemmatize):\n",
    "    corpus_cleaned_lemm_test.append(' '.join(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2bba2ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt_vec_uni = CountVectorizer(ngram_range=(1, 1))\n",
    "cnt_vec_uni.fit(corpus_cleaned_lemm_train)\n",
    "X_train_vec = cnt_vec_uni.transform(corpus_cleaned_lemm_train)\n",
    "X_test_vec = cnt_vec_uni.transform(corpus_cleaned_lemm_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a54530f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt_tfidf_uni = TfidfVectorizer(ngram_range=(1, 1), max_features=100)\n",
    "cnt_tfidf_uni.fit(corpus_cleaned_lemm_train)\n",
    "X_train_tf = cnt_tfidf_uni.transform(corpus_cleaned_lemm_train)\n",
    "X_test_tf = cnt_tfidf_uni.transform(corpus_cleaned_lemm_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d333aa20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     12218\n",
      "           1       1.00      1.00      1.00     12354\n",
      "\n",
      "    accuracy                           1.00     24572\n",
      "   macro avg       1.00      1.00      1.00     24572\n",
      "weighted avg       1.00      1.00      1.00     24572\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      3097\n",
      "           1       1.00      1.00      1.00      3046\n",
      "\n",
      "    accuracy                           1.00      6143\n",
      "   macro avg       1.00      1.00      1.00      6143\n",
      "weighted avg       1.00      1.00      1.00      6143\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train_vec, y_train)\n",
    "\n",
    "y_pred_train = model.predict(X_train_vec)\n",
    "print(classification_report(y_train, y_pred_train))\n",
    "\n",
    "y_pred_test = model.predict(X_test_vec)\n",
    "print(classification_report(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0f3cf8c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     12218\n",
      "           1       1.00      1.00      1.00     12354\n",
      "\n",
      "    accuracy                           1.00     24572\n",
      "   macro avg       1.00      1.00      1.00     24572\n",
      "weighted avg       1.00      1.00      1.00     24572\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97      3097\n",
      "           1       0.97      0.97      0.97      3046\n",
      "\n",
      "    accuracy                           0.97      6143\n",
      "   macro avg       0.97      0.97      0.97      6143\n",
      "weighted avg       0.97      0.97      0.97      6143\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_2 = LogisticRegression(max_iter=1000)\n",
    "model_2.fit(X_train_tf, y_train)\n",
    "\n",
    "y_pred_train_2 = model_2.predict(X_train_tf)\n",
    "print(classification_report(y_train, y_pred_train))\n",
    "\n",
    "y_pred_test_2 = model_2.predict(X_test_tf)\n",
    "print(classification_report(y_test, y_pred_test_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf21bc01",
   "metadata": {},
   "source": [
    "### Bi- Trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dda50d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt_vec_bi = CountVectorizer(ngram_range=(2, 3))\n",
    "cnt_vec_bi.fit(corpus_cleaned_lemm_train)\n",
    "X_train_vec_2 = cnt_vec_bi.transform(corpus_cleaned_lemm_train)\n",
    "X_test_vec_2 = cnt_vec_bi.transform(corpus_cleaned_lemm_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5bace4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt_tfidf_bi = TfidfVectorizer(ngram_range=(2, 3), max_features=100)\n",
    "cnt_tfidf_bi.fit(corpus_cleaned_lemm_train)\n",
    "X_train_tf_2 = cnt_tfidf_bi.transform(corpus_cleaned_lemm_train)\n",
    "X_test_tf_2 = cnt_tfidf_bi.transform(corpus_cleaned_lemm_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d898450a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     12218\n",
      "           1       1.00      1.00      1.00     12354\n",
      "\n",
      "    accuracy                           1.00     24572\n",
      "   macro avg       1.00      1.00      1.00     24572\n",
      "weighted avg       1.00      1.00      1.00     24572\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00      3097\n",
      "           1       0.99      1.00      1.00      3046\n",
      "\n",
      "    accuracy                           1.00      6143\n",
      "   macro avg       1.00      1.00      1.00      6143\n",
      "weighted avg       1.00      1.00      1.00      6143\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_3 = LogisticRegression(max_iter=1000)\n",
    "model_3.fit(X_train_vec_2, y_train)\n",
    "\n",
    "y_pred_train_3 = model_3.predict(X_train_vec_2)\n",
    "print(classification_report(y_train, y_pred_train_3))\n",
    "\n",
    "y_pred_test_3 = model_3.predict(X_test_vec_2)\n",
    "print(classification_report(y_test, y_pred_test_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eb259d4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.78      0.81     12218\n",
      "           1       0.80      0.86      0.83     12354\n",
      "\n",
      "    accuracy                           0.82     24572\n",
      "   macro avg       0.82      0.82      0.82     24572\n",
      "weighted avg       0.82      0.82      0.82     24572\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.76      0.80      3097\n",
      "           1       0.78      0.86      0.82      3046\n",
      "\n",
      "    accuracy                           0.81      6143\n",
      "   macro avg       0.81      0.81      0.81      6143\n",
      "weighted avg       0.81      0.81      0.81      6143\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_4 = LogisticRegression(max_iter=1000)\n",
    "model_4.fit(X_train_tf_2, y_train)\n",
    "\n",
    "y_pred_train_4 = model_4.predict(X_train_tf_2)\n",
    "print(classification_report(y_train, y_pred_train_4))\n",
    "\n",
    "y_pred_test_4 = model_4.predict(X_test_tf_2)\n",
    "print(classification_report(y_test, y_pred_test_4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc737d35",
   "metadata": {},
   "source": [
    "Pickle dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b69190ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_filename = 'model_log_vec.pkl'\n",
    "with open(model_filename, 'wb') as model_file:\n",
    "    pickle.dump(model, model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5d8313e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_filename = 'model_log_tfidf.pkl'\n",
    "with open(model_filename, 'wb') as model_file:\n",
    "    pickle.dump(model_2, model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "99298b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_filename = 'count_vectorizer_uni.pkl'\n",
    "with open(vec_filename, 'wb') as vec_file:\n",
    "    pickle.dump(cnt_vec_uni, vec_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c66c5830",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_filename = 'tfidf_vectorizer_uni.pkl'\n",
    "with open(vec_filename, 'wb') as vec_file:\n",
    "    pickle.dump(cnt_tfidf_uni, vec_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64c2cd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51e2556",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bdf2c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_filename = 'model.pkl'\n",
    "# with open(model_filename, 'rb') as model_file:\n",
    "#     loaded_model = pickle.load(model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd54e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vec_filename = 'vectorizer.pkl'\n",
    "# with open(vec_filename, 'rb') as vec_file:\n",
    "#     loaded_cnt_vec = pickle.load(vec_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scikit_venv",
   "language": "python",
   "name": "scikit_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
