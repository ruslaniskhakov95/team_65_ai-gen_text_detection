{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a8966c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/ruslanishakov/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/ruslanishakov/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/ruslanishakov/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/ruslanishakov/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from nltk import tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import string\n",
    "from collections import Counter\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24a7f8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_h = pd.read_csv('dataset/llm/train_essays.csv')\n",
    "df_palm = pd.read_csv('dataset/llm/LLM_generated_essay_PaLM.csv')\n",
    "df = pd.concat([df_h, df_palm], ignore_index=True)\n",
    "df['generated'] = df['generated'].astype('int')\n",
    "df['prompt_id'] = df['prompt_id'].astype('int')\n",
    "df = df.sample(2762)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "df.drop('id', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cef98534",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1420\n",
       "1    1342\n",
       "Name: prompt_id, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['prompt_id'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b728b767",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>text</th>\n",
       "      <th>generated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Cars have always been used to get from point A...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>The United States is a car-centric country. In...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>As the global concern for the environment incr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Voting time is here again and its time to cast...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Cars are a very, very common mode of transport...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2757</th>\n",
       "      <td>0</td>\n",
       "      <td>Cars are starting to become more and more expe...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2758</th>\n",
       "      <td>0</td>\n",
       "      <td>The advantages of limiting car usage has erupt...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2759</th>\n",
       "      <td>1</td>\n",
       "      <td>Dear Senator, I feel that we should change usi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2760</th>\n",
       "      <td>1</td>\n",
       "      <td>Dear Senator,\\n\\nI am writing to you today to ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2761</th>\n",
       "      <td>1</td>\n",
       "      <td>Dear Senator, The Presidential Election is one...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2762 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      prompt_id                                               text  generated\n",
       "0             0  Cars have always been used to get from point A...          0\n",
       "1             0  The United States is a car-centric country. In...          1\n",
       "2             0  As the global concern for the environment incr...          0\n",
       "3             1  Voting time is here again and its time to cast...          0\n",
       "4             0  Cars are a very, very common mode of transport...          0\n",
       "...         ...                                                ...        ...\n",
       "2757          0  Cars are starting to become more and more expe...          0\n",
       "2758          0  The advantages of limiting car usage has erupt...          0\n",
       "2759          1  Dear Senator, I feel that we should change usi...          0\n",
       "2760          1  Dear Senator,\\n\\nI am writing to you today to ...          1\n",
       "2761          1  Dear Senator, The Presidential Election is one...          0\n",
       "\n",
       "[2762 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab42d8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_clean_text(text):\n",
    "    tokens = tokenize.word_tokenize(text)\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    punct_chars = string.punctuation + \"'s\" + '\"\"' + '...' + \"''\" + '``'\n",
    "    filtered_tokens = [word.lower() for word in tokens if word not in stop_words and word not in punct_chars]\n",
    "    return filtered_tokens\n",
    "\n",
    "def lemmatize(tokens):\n",
    "    lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "    return [lemmatizer.lemmatize(token) for token in tokens]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a0d6b2",
   "metadata": {},
   "source": [
    "### prompt_id 0 - домен авто/города (car-free cities)\n",
    "### prompt_id 1 - домен политика США + письмо (write a letter to your senator about electoral college)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4d0a25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['text']\n",
    "y = df['generated']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f5fd804",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_cleaned_lemm = []\n",
    "for text in X.apply(tokenize_and_clean_text).apply(lemmatize):\n",
    "    corpus_cleaned_lemm.append(' '.join(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56aedae9",
   "metadata": {},
   "source": [
    "Load models and vectorizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "22619688",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_filename = 'model_log_vec.pkl'\n",
    "with open(model_filename, 'rb') as model_file:\n",
    "    loaded_model_vec = pickle.load(model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "85910e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_filename = 'model_log_tfidf.pkl'\n",
    "with open(model_filename, 'rb') as model_file:\n",
    "    loaded_model_tfidf = pickle.load(model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "37a593ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_filename = 'count_vectorizer_uni.pkl'\n",
    "with open(vec_filename, 'rb') as vec_file:\n",
    "    loaded_cnt_vec = pickle.load(vec_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9dd920c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_filename = 'tfidf_vectorizer_uni.pkl'\n",
    "with open(vec_filename, 'rb') as vec_file:\n",
    "    loaded_tfidf_vec = pickle.load(vec_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2db0c47",
   "metadata": {},
   "source": [
    "### LogReg Models based on CountVectorizer and TfIdfVectorizer respectively, trained on 30800 essays from ChatGPT-Human dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9600a748",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      1.00      0.70      1375\n",
      "           1       0.99      0.14      0.24      1387\n",
      "\n",
      "    accuracy                           0.57      2762\n",
      "   macro avg       0.76      0.57      0.47      2762\n",
      "weighted avg       0.77      0.57      0.47      2762\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "X_vec = loaded_cnt_vec.transform(corpus_cleaned_lemm)\n",
    "pred_vec = loaded_model_vec.predict(X_vec)\n",
    "print(print(classification_report(y, pred_vec)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5112ca98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.94      0.67      1375\n",
      "           1       0.70      0.13      0.22      1387\n",
      "\n",
      "    accuracy                           0.54      2762\n",
      "   macro avg       0.61      0.54      0.44      2762\n",
      "weighted avg       0.61      0.54      0.44      2762\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "X_tfidf = loaded_tfidf_vec.transform(corpus_cleaned_lemm)\n",
    "pred_tf = loaded_model_tfidf.predict(X_tfidf)\n",
    "print(print(classification_report(y, pred_tf)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e8f79d",
   "metadata": {},
   "source": [
    "### Own models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a8dfcaba",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['text']\n",
    "y = df['generated']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bc07e1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_cleaned_lemm_train = []\n",
    "corpus_cleaned_lemm_test = []\n",
    "for text in X_train.apply(tokenize_and_clean_text).apply(lemmatize):\n",
    "    corpus_cleaned_lemm_train.append(' '.join(text))\n",
    "for text in X_test.apply(tokenize_and_clean_text).apply(lemmatize):\n",
    "    corpus_cleaned_lemm_test.append(' '.join(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5ded7cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vec = TfidfVectorizer(ngram_range=(1, 1), max_features=100)\n",
    "tfidf_vec.fit(corpus_cleaned_lemm_train)\n",
    "X_train_vec = tfidf_vec.transform(corpus_cleaned_lemm_train)\n",
    "X_test_vec = tfidf_vec.transform(corpus_cleaned_lemm_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9cf24746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1046\n",
      "           1       1.00      1.00      1.00      1025\n",
      "\n",
      "    accuracy                           1.00      2071\n",
      "   macro avg       1.00      1.00      1.00      2071\n",
      "weighted avg       1.00      1.00      1.00      2071\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       329\n",
      "           1       1.00      1.00      1.00       362\n",
      "\n",
      "    accuracy                           1.00       691\n",
      "   macro avg       1.00      1.00      1.00       691\n",
      "weighted avg       1.00      1.00      1.00       691\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train_vec, y_train)\n",
    "\n",
    "y_pred_train = model.predict(X_train_vec)\n",
    "print(classification_report(y_train, y_pred_train))\n",
    "\n",
    "y_pred_test = model.predict(X_test_vec)\n",
    "print(classification_report(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba8ec5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_filename = 'model.pkl'\n",
    "# with open(model_filename, 'wb') as model_file:\n",
    "#     pickle.dump(model, model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d4bb75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vec_filename = 'vectorizer.pkl'\n",
    "# with open(vec_filename, 'wb') as vec_file:\n",
    "#     pickle.dump(cnt_vec, vec_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c872a18",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scikit_venv",
   "language": "python",
   "name": "scikit_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
