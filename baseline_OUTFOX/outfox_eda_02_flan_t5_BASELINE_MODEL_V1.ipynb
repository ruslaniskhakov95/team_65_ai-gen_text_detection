{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9d155923",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/ruslanishakov/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/ruslanishakov/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/ruslanishakov/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/ruslanishakov/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from nltk import tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score, recall_score\n",
    "import string\n",
    "from collections import Counter\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "198389fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>generated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Driverless cars have always been seen and thou...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Electoral College is only taking your pers...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Distance learning recently started being consi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Distractions while driving could lead to death...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Would having car free cities be easier for eve...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15395</th>\n",
       "      <td>Should students have classes from home, base i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15396</th>\n",
       "      <td>Driveress cars are in our future because of al...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15397</th>\n",
       "      <td>Are dreiverless cars a good idea for the futur...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15398</th>\n",
       "      <td>Sometimes school can be to much for a person. ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15399</th>\n",
       "      <td>summer project should be student-designed. For...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15400 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  generated\n",
       "0      Driverless cars have always been seen and thou...          0\n",
       "1      The Electoral College is only taking your pers...          0\n",
       "2      Distance learning recently started being consi...          0\n",
       "3      Distractions while driving could lead to death...          0\n",
       "4      Would having car free cities be easier for eve...          0\n",
       "...                                                  ...        ...\n",
       "15395  Should students have classes from home, base i...          0\n",
       "15396  Driveress cars are in our future because of al...          0\n",
       "15397  Are dreiverless cars a good idea for the futur...          0\n",
       "15398  Sometimes school can be to much for a person. ...          0\n",
       "15399  summer project should be student-designed. For...          0\n",
       "\n",
       "[15400 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pickl_h_train = pd.read_pickle('dataset/outfox/human/train_humans.pkl')\n",
    "pickl_h_test = pd.read_pickle('dataset/outfox/human/test_humans.pkl')\n",
    "pickl_h_valid = pd.read_pickle('dataset/outfox/human/valid_humans.pkl')\n",
    "df_human_test = pd.DataFrame(pickl_h_test)\n",
    "df_human_train = pd.DataFrame(pickl_h_train)\n",
    "df_human_valid = pd.DataFrame(pickl_h_valid)\n",
    "df_human = pd.concat([df_human_train, df_human_test, df_human_valid], ignore_index=True)\n",
    "df_human.rename(columns={0: 'text'}, inplace=True)\n",
    "df_human['generated'] = 0\n",
    "df_human"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb62a76a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>generated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Driverless motoring seems to be coming all of ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Several factors that contributed to its declin...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The most obvious benefit of distance learning ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>There are millions every quarter that decide o...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Many cities offer traffic bans during differen...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15395</th>\n",
       "      <td>It is hard for students to follow their class ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15396</th>\n",
       "      <td>This kind of software and technology used in c...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15397</th>\n",
       "      <td>Driverless cars would drastically reduce the a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15398</th>\n",
       "      <td>Online classes require the use of computer and...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15399</th>\n",
       "      <td>Having the option to choose our own assignment...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15400 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  generated\n",
       "0      Driverless motoring seems to be coming all of ...          1\n",
       "1      Several factors that contributed to its declin...          1\n",
       "2      The most obvious benefit of distance learning ...          1\n",
       "3      There are millions every quarter that decide o...          1\n",
       "4      Many cities offer traffic bans during differen...          1\n",
       "...                                                  ...        ...\n",
       "15395  It is hard for students to follow their class ...          1\n",
       "15396  This kind of software and technology used in c...          1\n",
       "15397  Driverless cars would drastically reduce the a...          1\n",
       "15398  Online classes require the use of computer and...          1\n",
       "15399  Having the option to choose our own assignment...          1\n",
       "\n",
       "[15400 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pickl_flan_train = pd.read_pickle('dataset/outfox/flan_t5/train_lms_flan.pkl')\n",
    "pickl_flan_test = pd.read_pickle('dataset/outfox/flan_t5/test_lms_flan.pkl')\n",
    "pickl_flan_valid = pd.read_pickle('dataset/outfox/flan_t5/valid_lms_flan.pkl')\n",
    "df_flan_train = pd.DataFrame(pickl_flan_train)\n",
    "df_flan_test = pd.DataFrame(pickl_flan_test)\n",
    "df_flan_valid = pd.DataFrame(pickl_flan_valid)\n",
    "df_flan = pd.concat([df_flan_train, df_flan_test, df_flan_valid], ignore_index=True)\n",
    "df_flan.rename(columns={0: 'text'}, inplace=True)\n",
    "df_flan['generated'] = 1\n",
    "df_flan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba315a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df_human, df_flan], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2fc490b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>generated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The need for students to complete a set period...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>It has been concluded that most extracurricula...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>In the modern days so much technology is being...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Luke Bomberger was a seagoing cowboy. He cross...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>We should be changing to the election by popul...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30795</th>\n",
       "      <td>The notion that cell phones should be used whi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30796</th>\n",
       "      <td>Whether drivers should be allowed use their ph...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30797</th>\n",
       "      <td>The most frequent criticism of the Electoral C...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30798</th>\n",
       "      <td>Why I think that Luke should join the program....</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30799</th>\n",
       "      <td>a democratic society needs to ensure every vot...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30715 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  generated\n",
       "0      The need for students to complete a set period...          1\n",
       "1      It has been concluded that most extracurricula...          1\n",
       "2      In the modern days so much technology is being...          0\n",
       "3      Luke Bomberger was a seagoing cowboy. He cross...          0\n",
       "4      We should be changing to the election by popul...          0\n",
       "...                                                  ...        ...\n",
       "30795  The notion that cell phones should be used whi...          0\n",
       "30796  Whether drivers should be allowed use their ph...          1\n",
       "30797  The most frequent criticism of the Electoral C...          1\n",
       "30798  Why I think that Luke should join the program....          0\n",
       "30799  a democratic society needs to ensure every vot...          1\n",
       "\n",
       "[30715 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.sample(30800).reset_index(drop=True)\n",
    "df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "010549d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_clean_text(text):\n",
    "    tokens = tokenize.word_tokenize(text)\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    punct_chars = string.punctuation + \"'s\" + '\"\"' + '...' + \"''\" + '``'\n",
    "    filtered_tokens = [word.lower() for word in tokens if word not in stop_words and word not in punct_chars]\n",
    "    return filtered_tokens\n",
    "\n",
    "def lemmatize(tokens):\n",
    "    lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "    return [lemmatizer.lemmatize(token) for token in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "41a58b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['text']\n",
    "y = df['generated']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fe57cd72",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_cleaned_lemm = []\n",
    "for text in X.apply(tokenize_and_clean_text).apply(lemmatize):\n",
    "    corpus_cleaned_lemm.append(' '.join(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2762ad90",
   "metadata": {},
   "source": [
    "Load models and vectorizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "635f810b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_filename = 'model_log_vec.pkl'\n",
    "with open(model_filename, 'rb') as model_file:\n",
    "    loaded_model_vec = pickle.load(model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c3a6986d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_filename = 'model_log_tfidf.pkl'\n",
    "with open(model_filename, 'rb') as model_file:\n",
    "    loaded_model_tfidf = pickle.load(model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fdfa13ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_filename = 'count_vectorizer_uni.pkl'\n",
    "with open(vec_filename, 'rb') as vec_file:\n",
    "    loaded_cnt_vec = pickle.load(vec_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "81cfddff",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_filename = 'tfidf_vectorizer_uni.pkl'\n",
    "with open(vec_filename, 'rb') as vec_file:\n",
    "    loaded_tfidf_vec = pickle.load(vec_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32af0b69",
   "metadata": {},
   "source": [
    "### LogReg Models based on CountVectorizer and TfIdfVectorizer respectively, trained on 30800 essays from ChatGPT-Human dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "edd60b86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      1.00      0.76     15400\n",
      "           1       1.00      0.36      0.53     15400\n",
      "\n",
      "    accuracy                           0.68     30800\n",
      "   macro avg       0.80      0.68      0.64     30800\n",
      "weighted avg       0.80      0.68      0.64     30800\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "X_vec = loaded_cnt_vec.transform(corpus_cleaned_lemm)\n",
    "pred_vec = loaded_model_vec.predict(X_vec)\n",
    "print(print(classification_report(y, pred_vec)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "24cd4e3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.98      0.84     15400\n",
      "           1       0.97      0.65      0.78     15400\n",
      "\n",
      "    accuracy                           0.82     30800\n",
      "   macro avg       0.86      0.82      0.81     30800\n",
      "weighted avg       0.86      0.82      0.81     30800\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "probs = loaded_model_vec.predict_proba(X_vec)\n",
    "new_pred = np.where(probs[:, 1] > 0.01, 1, 0)\n",
    "print(print(classification_report(y, new_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c6e19a6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01 0.6525324675324675 0.8176948051948052\n"
     ]
    }
   ],
   "source": [
    "RecMax = -1\n",
    "BestThr = -1\n",
    "BestAcc = -1\n",
    "\n",
    "for thr in np.arange(0, 1, 0.01):\n",
    "    pred = np.where(probs[:, 1] > thr, 1, 0)\n",
    "    rec = recall_score(y, pred)\n",
    "    acc = accuracy_score(y, pred)\n",
    "    if rec > RecMax and acc >= 0.6:\n",
    "        RecMax = rec\n",
    "        BestThr = thr\n",
    "        BestAcc = accuracy_score(y, pred)\n",
    "print(BestThr, RecMax, BestAcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e138a404",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "153d7209",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.97      0.75     15400\n",
      "           1       0.92      0.38      0.54     15400\n",
      "\n",
      "    accuracy                           0.67     30800\n",
      "   macro avg       0.77      0.67      0.64     30800\n",
      "weighted avg       0.77      0.67      0.64     30800\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "X_tfidf = loaded_tfidf_vec.transform(corpus_cleaned_lemm)\n",
    "pred_tf = loaded_model_tfidf.predict(X_tfidf)\n",
    "print(print(classification_report(y, pred_tf)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b5a0de5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.85      0.77     15400\n",
      "           1       0.81      0.64      0.72     15400\n",
      "\n",
      "    accuracy                           0.75     30800\n",
      "   macro avg       0.76      0.75      0.74     30800\n",
      "weighted avg       0.76      0.75      0.74     30800\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "probs_2 = loaded_model_tfidf.predict_proba(X_tfidf)\n",
    "new_pred_2 = np.where(probs_2[:, 1] > 0.15, 1, 0)\n",
    "print(print(classification_report(y, new_pred_2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ce108d",
   "metadata": {},
   "source": [
    "### Комментарий. Оптимальное соотношение recall и precision в виде максимума F1 достигается изменением порога классификации."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "013589ec",
   "metadata": {},
   "source": [
    "Own models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b89cb012",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['text']\n",
    "y = df['generated']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "80edd8f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_cleaned_lemm_train = []\n",
    "corpus_cleaned_lemm_test = []\n",
    "for text in X_train.apply(tokenize_and_clean_text).apply(lemmatize):\n",
    "    corpus_cleaned_lemm_train.append(' '.join(text))\n",
    "for text in X_test.apply(tokenize_and_clean_text).apply(lemmatize):\n",
    "    corpus_cleaned_lemm_test.append(' '.join(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "96c42f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(max_features=100)\n",
    "tfidf_vectorizer.fit(X_train)\n",
    "X_train_tfidf = tfidf_vectorizer.transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "502dcf9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.91      0.91     10705\n",
      "           1       0.91      0.91      0.91     10855\n",
      "\n",
      "    accuracy                           0.91     21560\n",
      "   macro avg       0.91      0.91      0.91     21560\n",
      "weighted avg       0.91      0.91      0.91     21560\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.89      0.91      4695\n",
      "           1       0.89      0.92      0.91      4545\n",
      "\n",
      "    accuracy                           0.91      9240\n",
      "   macro avg       0.91      0.91      0.91      9240\n",
      "weighted avg       0.91      0.91      0.91      9240\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "y_pred_train = model.predict(X_train_tfidf)\n",
    "print(classification_report(y_train, y_pred_train))\n",
    "print()\n",
    "\n",
    "y_pred = model.predict(X_test_tfidf)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7cb45231",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vec_bi = TfidfVectorizer(ngram_range=(2, 2), max_features=100)\n",
    "tfidf_vec_bi.fit(corpus_cleaned_lemm_train)\n",
    "X_train_tfidf = tfidf_vec_bi.transform(corpus_cleaned_lemm_train)\n",
    "X_test_tfidf = tfidf_vec_bi.transform(corpus_cleaned_lemm_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b6232b50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.75      0.75     10705\n",
      "           1       0.75      0.76      0.76     10855\n",
      "\n",
      "    accuracy                           0.75     21560\n",
      "   macro avg       0.75      0.75      0.75     21560\n",
      "weighted avg       0.75      0.75      0.75     21560\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.74      0.75      4695\n",
      "           1       0.74      0.77      0.75      4545\n",
      "\n",
      "    accuracy                           0.75      9240\n",
      "   macro avg       0.75      0.75      0.75      9240\n",
      "weighted avg       0.75      0.75      0.75      9240\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.68      0.74      4695\n",
      "           1       0.71      0.83      0.77      4545\n",
      "\n",
      "    accuracy                           0.75      9240\n",
      "   macro avg       0.76      0.75      0.75      9240\n",
      "weighted avg       0.76      0.75      0.75      9240\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_2 = LogisticRegression(max_iter=1000)\n",
    "model_2.fit(X_train_tfidf, y_train)\n",
    "\n",
    "y_pred_train_2 = model_2.predict(X_train_tfidf)\n",
    "print(classification_report(y_train, y_pred_train_2))\n",
    "\n",
    "y_pred_test_2 = model_2.predict(X_test_tfidf)\n",
    "print(classification_report(y_test, y_pred_test_2))\n",
    "\n",
    "probs = model_2.predict_proba(X_test_tfidf)\n",
    "pred_probs = np.where(probs[:, 1] > 0.45, 1, 0)\n",
    "print(classification_report(y_test, pred_probs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed67f3e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scikit_venv",
   "language": "python",
   "name": "scikit_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
